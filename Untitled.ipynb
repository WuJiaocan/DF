{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 查看测试集/训练集数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content_id</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XuPwKCnA2fqNh5vm</td>\n",
       "      <td>欧蓝德，价格便宜，森林人太贵啦！</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2jNbDn85goX3IuPE</td>\n",
       "      <td>楼主什么时候提的车，南昌优惠多少啊</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hLgEADQ8sUnvGFK9</td>\n",
       "      <td>吉林，2.5优惠20000，送三年九次保养，贴膜</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nZmM7LQsfr03wUaz</td>\n",
       "      <td>便宜2万的豪华特装，实用配制提升，优惠还给力，确实划算。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pwd8MnrthDqLZafe</td>\n",
       "      <td>如果实在想买就等车展期间，优惠2万，我24.98万入的2.5豪</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         content_id                          content\n",
       "0  XuPwKCnA2fqNh5vm             欧蓝德，价格便宜，森林人太贵啦！    \n",
       "1  2jNbDn85goX3IuPE                楼主什么时候提的车，南昌优惠多少啊\n",
       "2  hLgEADQ8sUnvGFK9         吉林，2.5优惠20000，送三年九次保养，贴膜\n",
       "3  nZmM7LQsfr03wUaz     便宜2万的豪华特装，实用配制提升，优惠还给力，确实划算。\n",
       "4  pwd8MnrthDqLZafe  如果实在想买就等车展期间，优惠2万，我24.98万入的2.5豪"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    测试集\n",
    "'''\n",
    "test_data = pd.read_csv(\"./test_public.csv\", encoding=\"utf-8\")\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content_id</th>\n",
       "      <th>content</th>\n",
       "      <th>subject</th>\n",
       "      <th>sentiment_value</th>\n",
       "      <th>sentiment_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vUXizsqexyZVRdFH</td>\n",
       "      <td>因为森林人即将换代，这套系统没必要装在一款即将换代的车型上，因为肯定会影响价格。</td>\n",
       "      <td>价格</td>\n",
       "      <td>0</td>\n",
       "      <td>影响</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4QroPd9hNfnCHVt7</td>\n",
       "      <td>四驱价格貌似挺高的，高的可以看齐XC60了，看实车前脸有点违和感。不过大众的车应该不会差。</td>\n",
       "      <td>价格</td>\n",
       "      <td>-1</td>\n",
       "      <td>高</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>QmqJ2AvM5GplaRyz</td>\n",
       "      <td>斯柯达要说质量，似乎比大众要好一点，价格也低一些，用料完全一样。我听说过野帝，但没听说过你说...</td>\n",
       "      <td>价格</td>\n",
       "      <td>1</td>\n",
       "      <td>低</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KMT1gFJiU4NWrVDn</td>\n",
       "      <td>这玩意都是给有钱任性又不懂车的土豪用的，这价格换一次我妹夫EP020可以换三锅了</td>\n",
       "      <td>价格</td>\n",
       "      <td>-1</td>\n",
       "      <td>有钱任性</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nVIlGd5yMmc37t1o</td>\n",
       "      <td>17价格忒高，估计也就是14-15左右。</td>\n",
       "      <td>价格</td>\n",
       "      <td>-1</td>\n",
       "      <td>高</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         content_id                                            content  \\\n",
       "0  vUXizsqexyZVRdFH           因为森林人即将换代，这套系统没必要装在一款即将换代的车型上，因为肯定会影响价格。   \n",
       "1  4QroPd9hNfnCHVt7      四驱价格貌似挺高的，高的可以看齐XC60了，看实车前脸有点违和感。不过大众的车应该不会差。   \n",
       "2  QmqJ2AvM5GplaRyz  斯柯达要说质量，似乎比大众要好一点，价格也低一些，用料完全一样。我听说过野帝，但没听说过你说...   \n",
       "3  KMT1gFJiU4NWrVDn           这玩意都是给有钱任性又不懂车的土豪用的，这价格换一次我妹夫EP020可以换三锅了   \n",
       "4  nVIlGd5yMmc37t1o                            17价格忒高，估计也就是14-15左右。      \n",
       "\n",
       "  subject  sentiment_value sentiment_word  \n",
       "0      价格                0             影响  \n",
       "1      价格               -1              高  \n",
       "2      价格                1              低  \n",
       "3      价格               -1           有钱任性  \n",
       "4      价格               -1              高  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    训练集\n",
    "'''\n",
    "train_data = pd.read_csv(\"./train.csv\", encoding=\"utf-8\")\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9947条记录\n",
    "# train_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['价格', '配置', '操控', '舒适性', '油耗', '动力', '内饰', '安全性', '空间', '外观'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"subject\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0, -1,  1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"sentiment_value\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_len: 59.04053075995175\n",
      "min_len: 10\n",
      "max_len 200\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    查看训练集合每句话的最长/最短长度/平均长度\n",
    "'''\n",
    "\n",
    "total_len = 0\n",
    "avg_len = 0 \n",
    "min_len = len(train_data[\"content\"][0])\n",
    "max_len = 0\n",
    "length = 0\n",
    "for line in train_data[\"content\"]:  # 共8290非重复的样本\n",
    "    if line:\n",
    "        length = len(line)\n",
    "        total_len += length\n",
    "        if length < min_len:\n",
    "            min_len = length\n",
    "        if length > max_len:\n",
    "            max_len = length\n",
    "            \n",
    "print(\"avg_len:\", total_len/8290)\n",
    "print(\"min_len:\", min_len)\n",
    "print(\"max_len\", max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neutral_data = train_data[[\"content\"]][train_data[\"sentiment_value\"]==0] #  中立 6661条\n",
    "# pd.DataFrame(neutral_data[\"content\"].unique())                           # 剔除重复，6001条 意思是一句评论，可能有若干不同的主题，分若干行写了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# negative_data = train_data[[\"content\"]][train_data[\"sentiment_value\"] == -1] #  负 1616条\n",
    "# pd.DataFrame(negative_data[\"content\"].unique())                              # 剔除重复，1401条"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# positive_data = train_data[[\"content\"]][train_data[\"sentiment_value\"] == 1] #  正 1670条\n",
    "# pd.DataFrame(positive_data[\"content\"].unique())                             # 提出重复，1312条"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    加载停用词\n",
    "'''\n",
    "stop_words = []\n",
    "with open(\"./stop_words.txt\", \"r\", encoding=\"utf=8\") as stop_data:\n",
    "    for line in stop_data.readlines():\n",
    "        if line:\n",
    "            line = line.strip()\n",
    "            stop_words.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from /home/lx/anaconda3/lib/python3.6/site-packages/jieba/dict.txt ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.653855562210083 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    训练集分词\n",
    "'''\n",
    "import jieba\n",
    "cut_train_data = []\n",
    "for line in train_data[\"content\"]:\n",
    "    cut_train_data.append(\" \".join([word for word in jieba.cut(line) \n",
    "                                    if word not in stop_words and word != \" \"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9947"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cut_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    获取训练集中的情感词,作为测试集中写情感词的user_dict.txt\n",
    "'''\n",
    "trainDataSentimentWord = list(pd.Series(train_data[\"sentiment_word\"]).unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    将训练集情感词中的\" \"去除，因为训练集不是所有都有情感词，有的行为空\n",
    "'''\n",
    "while ' ' in trainDataSentimentWord:\n",
    "    trainDataSentimentWord.remove(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    测试集分词\n",
    "'''\n",
    "cut_test_data = []\n",
    "for line in test_data[\"content\"]:\n",
    "    cut_test_data.append(\" \".join([word for word in jieba.cut(line) \n",
    "                                   if word not in stop_words and word != \" \"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2364"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cut_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    获取测试集每句话的情感词，规则是：\n",
    "        如果测试集的分词存在训练集的情感词中，则将出现的第一个作为测试集的情感词；\n",
    "        否则，将测试集的第一个分词作为情感词。\n",
    "'''\n",
    "testDataKeywords = []\n",
    "for sent in cut_test_data:\n",
    "    lineKeywords = []\n",
    "    word = sent.split(\" \")[0]\n",
    "    for cutwords in sent.split(\" \"):\n",
    "        if cutwords in trainDataSentimentWord:\n",
    "            lineKeywords.append(cutwords)\n",
    "            break\n",
    "    if lineKeywords:\n",
    "        testDataKeywords.extend(lineKeywords)\n",
    "    else:\n",
    "        testDataKeywords.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2364"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testDataKeywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 划分训练/测试集，提取特征，加载模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = cut_train_data\n",
    "train_y_subject = list(train_data[\"subject\"])\n",
    "train_y_sentiment_value = list(train_data[\"sentiment_value\"])\n",
    "test_X = cut_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "tfidf = TfidfVectorizer(token_pattern='(?u)\\\\b\\\\w+\\\\b', min_df=1, max_df=1.0, ngram_range=(1,2))\n",
    "tfidf.fit(train_X)\n",
    "\n",
    "tfidf_train_X = tfidf.transform(train_X)\n",
    "tfidf_test_X = tfidf.transform(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = LinearSVC()\n",
    "svm.fit(tfidf_train_X, train_y_subject)\n",
    "prediction_subject = svm.predict(tfidf_test_X)\n",
    "\n",
    "svm.fit(tfidf_train_X, train_y_sentiment_value)\n",
    "prediction_sentiment_value = svm.predict(tfidf_test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2364"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prediction_subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2364"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prediction_sentiment_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['价格', '价格', '价格', '价格', '价格', '价格', '价格', '价格', '价格', '配置']"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(prediction_subject)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['价格', '配置', '舒适性', '动力', '油耗', '内饰', '安全性', '操控', '空间', '外观'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(prediction_subject).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(prediction_sentiment_value)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  0, -1])"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(prediction_sentiment_value).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2364"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_id = list(test_data[\"content_id\"])\n",
    "len(content_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./submit.csv\", \"w\", encoding=\"utf-8\") as submit:\n",
    "    submit.write(\"content_id\" + \",\" +\"subject\" + \",\" + \n",
    "                                             \"sentiment_value\" + \",\" + \"sentiment_word\" + \"\\n\")\n",
    "    for ids, sub, value, word in zip(content_id, list(prediction_subject),\n",
    "                                  list(prediction_sentiment_value), testDataKeywords):\n",
    "        submit.write(str(ids) + \",\" + str(sub) + \",\" +\n",
    "                                      str(value) + \",\" + str(word)  + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
